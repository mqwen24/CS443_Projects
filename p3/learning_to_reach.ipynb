{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a64bc0ed",
   "metadata": {},
   "source": [
    "**YOUR NAMES HERE**\n",
    "\n",
    "Spring 2023\n",
    "\n",
    "CS 443: Bio-inspired Machine Learning\n",
    "\n",
    "#### Week 3: Training model arm to reach for targets\n",
    "\n",
    "# Project 3: Outstar Learning and Motor Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feed4718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(['seaborn-v0_8-colorblind', 'seaborn-v0_8-darkgrid'])\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.show()\n",
    "\n",
    "np.set_printoptions(suppress=True, precision=3)\n",
    "\n",
    "# Automatically reload external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c474aa79",
   "metadata": {},
   "source": [
    "## Task 5: Train arm to reach for targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a330a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joint import Joint, EndEffector\n",
    "from motor_neurons import MotorNeurons\n",
    "from muscles import Muscles\n",
    "from model_arm import Arm\n",
    "from outstar import Outstar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e3b1aa",
   "metadata": {},
   "source": [
    "### 5a. Implement and visualize the self-supervised training process\n",
    "\n",
    "- Implement the `get_movement_dir` and `train` `Arm` methods in `model_arm.py`.\n",
    "- Fill in the `make_arm` function below to handle creating the 3-jointed model arm starting in its default posture. Then in the next cell, make the arm and train it with default hyperparameters with a learning rate of `0.02`.\n",
    "\n",
    "You should see an animation of your model arm babbling (similar to Week 1). Every 20 epochs you should see the posture of arm suddenly change. \n",
    "\n",
    "#### Review: Default posture joint and hand specifications\n",
    "\n",
    "*This is identical to the specs from Week 1.*\n",
    "\n",
    "**Shoulder:** Initial joint angle of $\\pi/8$. Joint angle limited to the range $(-\\pi/2, \\pi)$.\n",
    "\n",
    "**Elbow:** Initial joint angle of $\\pi/2$. Joint angle limited to the range $(0, \\pi)$. Length of upper arm (connecting elbow and shoulder) is 28 cm.\n",
    "\n",
    "**Wrist:** Initial joint angle of $\\pi/3$. Joint angle limited to the range $(-\\pi/2, \\pi/2)$. Length of lower arm (connecting wrist and elbow) is 28 cm.\n",
    "\n",
    "**Hand:** Distance from end-of-hand to wrist is 16 cm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32266ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_arm(lr):\n",
    "    '''Makes and returns an `Arm` object with the default initial arm posture.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    lr: float. The learning rate used by the Outstar neural network.\n",
    "    \n",
    "    Returns:\n",
    "    -----------\n",
    "    Arm. The arm object.\n",
    "    '''\n",
    "    np.random.seed(0)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0701b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# TODO: Make Arm object with learning rate of 0.02\n",
    "\n",
    "\n",
    "# TODO: Train your Arm below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ededdc",
   "metadata": {},
   "source": [
    "### 5b. Complete a full training session\n",
    "\n",
    "Use a learning rate of `0.02` again, but this time train for `10000` epochs. Turn off visualization on this training run so that the network trains much faster!\n",
    "\n",
    "**Note:**\n",
    "- Your network should at most take a few minutes to train.\n",
    "- Use `print_every` to print out progress. Not too often otherwise the print outs will slow down training. Not too infrequently otherwise there's little point including the print outs :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdfa4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82193c47",
   "metadata": {},
   "source": [
    "### 5c. Implement `test`: Run network in prediction mode to reach for targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba8fb5a",
   "metadata": {},
   "source": [
    "#### Test: Use trained arm to reach for four targets\n",
    "\n",
    "If everything is working as expected, you should see the hand move to successfully intercept each target one-by-one!\n",
    "\n",
    "*Remember to pass all the target positions into the `ArmPlot` update method so that they appear on the plot as red disks!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e58b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "all_target_pos = np.array([[-20, 60], [20, 60], [-20, 20], [20, 20]])\n",
    "arm.test(all_target_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c57e1a",
   "metadata": {},
   "source": [
    "### 5d. Questions\n",
    "\n",
    "**Question 9:** Now that you have hands-on experience seeing how the training protocol translates to arm reaching capability, in your own words briefly describe the self-supervised learning process â€” how the arm learns by generating its own data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d4d843",
   "metadata": {},
   "source": [
    "**Answer 9:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e28dee",
   "metadata": {},
   "source": [
    "## Task 6: Self-designed experiment\n",
    "\n",
    "Explore the capabilities of your model arm in an experiment that you design. **This task does not require you implementing any new features â€” keep it simple!** There are many interesting questions to explore by simplying changing hyperparameters and interpreting what you find. Briefly report what the idea behind the experiment (i.e. why did you run the experiment?), what you thought would happen (i.e. your hypothesis), and what you found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789abea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8964b6fa",
   "metadata": {},
   "source": [
    "## Extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2422ee",
   "metadata": {},
   "source": [
    "### 1. Make the visualization fancier\n",
    "\n",
    "Color code current target reached for, reveal only the next target, include a dynamic plot of distance to the target, mark previous targets, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48e2fa1",
   "metadata": {},
   "source": [
    "### 2. Hyperparameter exploration\n",
    "\n",
    "Do a hyperparameter search. Because this is not a supervised learning task, you will need to invent your own performance metric the quantifies how well the model arm performs (e.g. time to grasp target)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b7d5fb",
   "metadata": {},
   "source": [
    "### 3. Learning and development\n",
    "\n",
    "Explore more extensively how degree of training (\"development\") influences how well the model arm reaches. Evaluate this using your own metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c2a4cd",
   "metadata": {},
   "source": [
    "### 4.Implement mini-batch support for faster training\n",
    "\n",
    "In the training algorithm, each epoch corresponds to a new random starting position for the arm, which is then followed by `n_babbles` babbles. In the project, this is implemented sequentially (SGD style), however, training can happen in mini-batches, which should speed up training. To add support for mini-batches, the idea is to create a training set in advance of the training process wherein the random muscle activations, joint angles, and positions are precomputed (each combination of these become a \"training sample\"). This is basically what you do one-by-one in `train` currently. As long as you store both the previous and current position of the arm before/after each babble (or just make the net movement direction the feature), you should be able to train the Outstar network with samples in any shuffled order.\n",
    "\n",
    "Another important step in adding mini-batch support is updating the `net_in`, `net_act`, and weight update code to support the batch dimension.\n",
    "\n",
    "If mini-batch support is added, it would be interesting to compare training time vs. the approach in the base project.\n",
    "\n",
    "It would also be interesting to explore whether writing the training code (with mini-batch support) in TensorFlow would further decrease training time.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bd9ca8",
   "metadata": {},
   "source": [
    "### 5. Effect of source and sink magnitude\n",
    "\n",
    "In the simple network used in Task 4, the source activations were consistent in train and prediction phases. Analyze what happens as the magnitude of the source activations fluctuate over presentations in train and/or prediction. What are essential conditions for learning to occur?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7bead9",
   "metadata": {},
   "source": [
    "### 6. Randomness in feature vectors\n",
    "\n",
    "In the simple network used in Task 4, both source and sink activation feature vectors were constant across presentations. Explore how/what the network learns when randomness is added to each feature vector so that it differs on each presentation but averages out to be the vectors you used earlier over many repeated presentations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bed221f",
   "metadata": {},
   "source": [
    "### 7. More elaborate experiment\n",
    "\n",
    "Design a more elaborate experiment than the one used in Task 6."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
